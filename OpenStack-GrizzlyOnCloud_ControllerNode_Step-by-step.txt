# Install OpenStack Grizzly on Ubuntu 12.04 LTS
#
# Controller setup steps on a Cloud based VM with:
# 4GB RAM, 2CPU
# eth0 - Public Interface [192.237.168.211]
# eth1 - Private Interface [10.208.143.46]
# /dev/xvda [150GB]
# /dev/xvdb [100GB] (Cinder Logical Volume]
#
# bugtrack al.kari@detacloud.com || @detacloud
# 2013-08-25

# Check if nested virtualization is supported. Use qemu if not.
apt-get install -y cpu-checker
kvm-ok

egrep -c '(vmx|svm)' /proc/cpuinfo

# use qemu if 0, else use kvm
# nova-compute-kvm requires that your CPU supports hardware-assisted virtualization (HVM) such as Intel VT-x or AMD-V. If your CPU does not support this, or if you are already running in a virtualized environment, you can instead use the nova-compute-qemu package. This package provides software-based virtualization.


### Replace the following credentials for production install:
# notmysql
# notkeystone
# notquantum
# notnova
# notcinder
# notglance
# ADMIN
# MyProject
# myuser / mypassword
# myadmin / mypassword
###

# Add a user
adduser mystack
# Enter: mypassword
apt-get install sudo -y
echo "mystack ALL=(ALL) NOPASSWD: ALL" >> /etc/sudoers

# 3 - Install supporting packages
sudo apt-get -y install curl ntp

# 4 - Synchronize time
sudo ntpdate -u 129.6.15.30 

sudo sed -i "s/#net.ipv4.conf.default.rp_filter=1/net.ipv4.conf.default.rp_filter=0/g" /etc/sysctl.conf
sudo sed -i "s/#net.ipv4.conf.all.rp_filter=1/net.ipv4.conf.all.rp_filter=0/g" /etc/sysctl.conf

sysctl -p

service networking restart

# Verify network configurations
ip a

# Set hostname
sudo hostname controller
echo controller > /etc/hostname

# Replace 'ubuntu' below with existing host name
sudo sed -i 's/ubuntu/controller/g' /etc/hosts

sudo shutdown -r now

# LOGIN WITH NEW USER: mystack/mypassword

sudo su

# Store Public IP Address
PUBLIC_IP="$(ifconfig | grep -A 1 'eth0' | tail -1 | cut -d ':' -f 2 | cut -d ' ' -f 1)"

# Store Private IP Address 
PRIVATE_IP="$(ifconfig | grep -A 1 'eth1' | tail -1 | cut -d ':' -f 2 | cut -d ' ' -f 1)"

# 5- Enable the Cloud Archive repository
cat >> /etc/apt/sources.list.d/grizzly.list <<EOF
deb http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/grizzly main
EOF

sudo apt-get install ubuntu-cloud-keyring

# 6 - Update all
sudo apt-get update -y && apt-get upgrade -y


####################################################################################
####################################################################################
#				MySQL and RabbitMQ
####################################################################################
####################################################################################

# 7 - Preseed the MySQL install
cat <<EOF | sudo debconf-set-selections
mysql-server-5.1 mysql-server/root_password password notmysql
mysql-server-5.1 mysql-server/root_password_again password notmysql
mysql-server-5.1 mysql-server/start_on_boot boolean true
EOF

# 8 - Install packages and dependencies
sudo apt-get install -y rabbitmq-server mysql-server python-mysqldb

# 9- Configure MySQL to listen on all interfaces
sudo sed -i 's/127.0.0.1/0.0.0.0/g' /etc/mysql/my.cnf
sudo service mysql restart


####################################################################################
####################################################################################
#				Identity Service (Keystone)
####################################################################################
####################################################################################

# 11 - Install Keystone
sudo apt-get install -y keystone

# 12 - Delete the keystone.db file created in the /var/lib/keystone directory.
sudo rm /var/lib/keystone/keystone.db

# Verify the OpenStack version (Grizzly == 2013.1)
sudo dpkg -p keystone | grep "Version:"

# Create a database for keystone
sudo mysql -u root -pnotmysql -e "CREATE DATABASE keystone;"
sudo mysql -u root -pnotmysql -e "GRANT ALL ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'notkeystone';"
sudo mysql -u root -pnotmysql -e "GRANT ALL ON keystone.* TO 'keystone'@'$PRIVATE_IP' IDENTIFIED BY 'notkeystone';"
sudo mysql -u root -pnotmysql -e "GRANT ALL ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'notkeystone';"


# Configure keystone to use MySQL
sudo sed -i "s|connection = sqlite:////var/lib/keystone/keystone.db|connection = mysql://keystone:notkeystone@$PRIVATE_IP/keystone|g" /etc/keystone/keystone.conf

# Restart keystone service
sudo service keystone restart

# Verify keystone service successfully restarted
sudo pgrep -l keystone

# Initialize the database schema
sudo -u keystone keystone-manage db_sync

# Export the keystone "admin" credentials to add the first users
export SERVICE_TOKEN=ADMIN
export SERVICE_ENDPOINT=http://$PRIVATE_IP:35357/v2.0

# Create new tenants (The services tenant will be used later when configuring services to use keystone)
TENANT_ID=`keystone tenant-create --name MyProject | awk '/ id / { print $4 }'`
SERVICE_TENANT_ID=`keystone tenant-create --name Services | awk '/ id / { print $4 }'`
# 22- Verify
keystone tenant-list

# Create admin role
ADMIN_ROLE_ID=`keystone role-create --name admin | awk '/ id / { print $4 }'`

# Create new users
MEMBER_USER_ID=`keystone user-create --tenant-id $TENANT_ID --name myuser --pass mypassword | awk '/ id / { print $4 }'`
ADMIN_USER_ID=`keystone user-create --tenant-id $TENANT_ID --name myadmin --pass mypassword | awk '/ id / { print $4 }'`

# Grant admin role
keystone user-role-add --user-id $ADMIN_USER_ID --tenant-id $TENANT_ID --role-id $ADMIN_ROLE_ID
# 25 - Verify
keystone user-list

# List the new tenant, users, roles, and role assigments
keystone tenant-list
keystone role-list
keystone user-list --tenant-id $TENANT_ID
keystone user-role-list --tenant-id $TENANT_ID --user-id $MEMBER_USER_ID
keystone user-role-list --tenant-id $TENANT_ID --user-id $ADMIN_USER_ID

# Populate the services in the service catalog
KEYSTONE_SVC_ID=`keystone service-create --name=keystone --type=identity --description="Keystone Identity Service" | awk '/ id / { print $4 }'`
GLANCE_SVC_ID=`keystone service-create --name=glance --type=image --description="Glance Image Service" | awk '/ id / { print $4 }'`
QUANTUM_SVC_ID=`keystone service-create --name=quantum --type=network --description="Quantum Network Service" | awk '/ id / { print $4 }'`
NOVA_SVC_ID=`keystone service-create --name=nova --type=compute --description="Nova Compute Service" | awk '/ id / { print $4 }'`
CINDER_SVC_ID=`keystone service-create --name=cinder --type=volume --description="Cinder Volume Service" | awk '/ id / { print $4 }'`

# List the new services
keystone service-list

# Populate the endpoints in the service catalog
keystone endpoint-create --region RegionOne --service-id=$KEYSTONE_SVC_ID --publicurl=http://$PRIVATE_IP:5000/v2.0 --internalurl=http://$PRIVATE_IP:5000/v2.0 --adminurl=http://$PRIVATE_IP:35357/v2.0
keystone endpoint-create --region RegionOne --service-id=$GLANCE_SVC_ID --publicurl=http://$PRIVATE_IP:9292/v1 --internalurl=http://$PRIVATE_IP:9292/v1 --adminurl=http://$PRIVATE_IP:9292/v1
keystone endpoint-create --region RegionOne --service-id=$QUANTUM_SVC_ID --publicurl=http://$PRIVATE_IP:9696/ --internalurl=http://$PRIVATE_IP:9696/ --adminurl=http://$PRIVATE_IP:9696/
keystone endpoint-create --region RegionOne --service-id=$NOVA_SVC_ID --publicurl="http://$PRIVATE_IP:8774/v2/%(tenant_id)s" --internalurl="http://$PRIVATE_IP:8774/v2/%(tenant_id)s" --adminurl="http://$PRIVATE_IP:8774/v2/%(tenant_id)s"
keystone endpoint-create --region RegionOne --service-id=$CINDER_SVC_ID --publicurl="http://$PRIVATE_IP:8776/v1/%(tenant_id)s" --internalurl="http://$PRIVATE_IP:8776/v1/%(tenant_id)s" --adminurl="http://$PRIVATE_IP:8776/v1/%(tenant_id)s"

# List the new endpoints
keystone endpoint-list

# The keystone "admin" credentials are no longer needed
unset SERVICE_TOKEN
unset SERVICE_ENDPOINT

# Verify identity service is functioning
curl -d '{"auth": {"tenantName": "MyProject", "passwordCredentials": {"username": "myuser", "password": "mypassword"}}}' -H "Content-type: application/json" http://$PRIVATE_IP:5000/v2.0/tokens | python -m json.tool
curl -d '{"auth": {"tenantName": "MyProject", "passwordCredentials": {"username": "myadmin", "password": "mypassword"}}}' -H "Content-type: application/json" http://$PRIVATE_IP:5000/v2.0/tokens | python -m json.tool

# Create the 'user' and 'admin' credentials
mkdir ~/credentials

cat >> ~/credentials/user <<EOF
export OS_USERNAME=myuser
export OS_PASSWORD=mypassword
export OS_TENANT_NAME=MyProject
export OS_AUTH_URL=http://$PRIVATE_IP:5000/v2.0/
export OS_REGION_NAME=RegionOne
export OS_NO_CACHE=1
EOF

cat >> ~/credentials/admin <<EOF
export OS_USERNAME=myadmin
export OS_PASSWORD=mypassword
export OS_TENANT_NAME=MyProject
export OS_AUTH_URL=http://$PRIVATE_IP:5000/v2.0/
export OS_REGION_NAME=RegionOne
export OS_NO_CACHE=1
EOF

# Use the 'admin' credentials
source ~/credentials/admin

cat >> ~/.bashrc <<EOF
export SERVICE_TENANT_ID=$SERVICE_TENANT_ID
export ADMIN_ROLE_ID=$ADMIN_ROLE_ID
EOF


####################################################################################
####################################################################################
#				Image Servie (Glance)
####################################################################################
####################################################################################

# Install the image service (glance)
sudo apt-get install -y glance

# Use the 'admin' credentials to add the glance service user in keystone
source ~/credentials/admin

# Create glance service user in the services tenant
GLANCE_USER_ID=`keystone user-create --tenant-id $SERVICE_TENANT_ID --name glance --pass notglance | awk '/ id / { print $4 }'`

# Grant admin role to glance service user
keystone user-role-add --user-id $GLANCE_USER_ID --tenant-id $SERVICE_TENANT_ID --role-id $ADMIN_ROLE_ID

# List the new user and role assigment
keystone user-list --tenant-id $SERVICE_TENANT_ID
keystone user-role-list --tenant-id $SERVICE_TENANT_ID --user-id $GLANCE_USER_ID

# Create a database for glance
mysql -u root -pnotmysql -e "CREATE DATABASE glance;"
mysql -u root -pnotmysql -e "GRANT ALL ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'notglance';"
mysql -u root -pnotmysql -e "GRANT ALL ON glance.* TO 'glance'@'$PRIVATE_IP' IDENTIFIED BY 'notglance';"
mysql -u root -pnotmysql -e "GRANT ALL ON glance.* TO 'glance'@'%' IDENTIFIED BY 'notglance';"

# Configure the glance-api service
sudo sed -i "s|sql_connection = sqlite:////var/lib/glance/glance.sqlite|sql_connection = mysql://glance:notglance@$PRIVATE_IP/glance|g" /etc/glance/glance-api.conf
sudo sed -i "s/auth_host = 127.0.0.1/auth_host = $PRIVATE_IP/g" /etc/glance/glance-api.conf
sudo sed -i 's/%SERVICE_TENANT_NAME%/Services/g' /etc/glance/glance-api.conf
sudo sed -i 's/%SERVICE_USER%/glance/g' /etc/glance/glance-api.conf
sudo sed -i 's/%SERVICE_PASSWORD%/notglance/g' /etc/glance/glance-api.conf
sudo sed -i 's/#flavor=/flavor = keystone/g' /etc/glance/glance-api.conf

# Configure the glance-registry service
sudo sed -i "s|sql_connection = sqlite:////var/lib/glance/glance.sqlite|sql_connection = mysql://glance:notglance@$PRIVATE_IP/glance|g" /etc/glance/glance-registry.conf
sudo sed -i "s/auth_host = 127.0.0.1/auth_host = $PRIVATE_IP/g" /etc/glance/glance-registry.conf
sudo sed -i 's/%SERVICE_TENANT_NAME%/Services/g' /etc/glance/glance-registry.conf
sudo sed -i 's/%SERVICE_USER%/glance/g' /etc/glance/glance-registry.conf
sudo sed -i 's/%SERVICE_PASSWORD%/notglance/g' /etc/glance/glance-registry.conf
sudo sed -i 's/#flavor=/flavor = keystone/g' /etc/glance/glance-registry.conf

# Restart glance services
sudo service glance-registry restart
sudo service glance-api restart

# Verify glance services successfully restarted
pgrep -l glance

# Initialize the database schema. A deprecation warning is OK...
sudo -u glance glance-manage db_sync

# Download some images
mkdir ~/images
wget https://launchpad.net/cirros/trunk/0.3.0/+download/cirros-0.3.0-x86_64-uec.tar.gz -qO- | tar zxC ~/images
wget https://launchpad.net/cirros/trunk/0.3.0/+download/cirros-0.3.0-x86_64-disk.img -O ~/images/cirros-0.3.1~pre4-x86_64-disk.img
wget http://cloud-images.ubuntu.com/precise/current/precise-server-cloudimg-amd64-disk1.img -O ~/images/precise.qcow2.img

# Use the 'user' credentials
source ~/credentials/user

# Register a three part image (amazon style, separate kernal and ramdisk)
KERNEL_ID=`glance image-create --name "cirros-threepart-kernel" --disk-format aki --container-format aki --is-public True --file ~/images/cirros-0.3.0-x86_64-vmlinuz | awk '/ id / { print $4 }'`
RAMDISK_ID=`glance image-create --name "cirros-threepart-ramdisk" --disk-format ari --container-format ari --is-public True --file ~/images/cirros-0.3.0-x86_64-initrd | awk '/ id / { print $4 }'`
IMAGE_ID_1=`glance image-create --name "cirros-threepart" --disk-format ami --container-format ami --is-public True --property kernel_id=$KERNEL_ID --property ramdisk_id=$RAMDISK_ID --file ~/images/cirros-0.3.0-x86_64-blank.img | awk '/ id / { print $4 }'`

# Register a qcow2 image
IMAGE_ID_2=`glance image-create --name "cirros-qcow2" --disk-format qcow2 --container-format bare --is-public True --file ~/images/cirros-0.3.1~pre4-x86_64-disk.img | awk '/ id / { print $4 }'`

IMAGE_ID_3=`glance image-create --name "precise-qcow2" --disk-format qcow2 --container-format bare --is-public True --file ~/images/precise.qcow2.img | awk '/ id / { print $4 }'`

# Verify the images exist in glance
glance image-list

# Examine details of images
glance image-show $IMAGE_ID_1
glance image-show $IMAGE_ID_2
glance image-show $IMAGE_ID_3

cat >> ~/.bashrc <<EOF
export IMAGE_ID_1=$IMAGE_ID_1
export IMAGE_ID_2=$IMAGE_ID_2
export IMAGE_ID_3=$IMAGE_ID_3
EOF


####################################################################################
####################################################################################
#				Networking service (Neutron[Quantum])
####################################################################################
####################################################################################


# Install dependencies
sudo apt-get install -y openvswitch-switch

# Install the network service (quantum)
sudo apt-get install -y quantum-server quantum-plugin-openvswitch

# Install the network service (quantum) agents
sudo apt-get install -y quantum-plugin-openvswitch-agent quantum-dhcp-agent quantum-l3-agent

# Create a database for quantum
mysql -u root -pnotmysql -e "CREATE DATABASE quantum;"
mysql -u root -pnotmysql -e "GRANT ALL ON quantum.* TO 'quantum'@'localhost' IDENTIFIED BY 'notquantum';"
mysql -u root -pnotmysql -e "GRANT ALL ON quantum.* TO 'quantum'@'$PRIVATE_IP' IDENTIFIED BY 'notquantum';"
mysql -u root -pnotmysql -e "GRANT ALL ON quantum.* TO 'quantum'@'%' IDENTIFIED BY 'notquantum';"

# Configure the quantum OVS plugin
sudo sed -i "s|sql_connection = sqlite:////var/lib/quantum/ovs.sqlite|sql_connection = mysql://quantum:notquantum@$PRIVATE_IP/quantum|g"  /etc/quantum/plugins/openvswitch/ovs_quantum_plugin.ini
sudo sed -i 's/# Default: enable_tunneling = False/enable_tunneling = True/g' /etc/quantum/plugins/openvswitch/ovs_quantum_plugin.ini
sudo sed -i 's/# Example: tenant_network_type = gre/tenant_network_type = gre/g' /etc/quantum/plugins/openvswitch/ovs_quantum_plugin.ini
sudo sed -i 's/# Example: tunnel_id_ranges = 1:1000/tunnel_id_ranges = 1:1000/g' /etc/quantum/plugins/openvswitch/ovs_quantum_plugin.ini
sudo sed -i "s/# Default: local_ip =/local_ip = $PUBLIC_IP/g" /etc/quantum/plugins/openvswitch/ovs_quantum_plugin.ini
sudo sed -i "s/# firewall_driver/firewall_driver/g" /etc/quantum/plugins/openvswitch/ovs_quantum_plugin.ini

# Use the 'admin' credentials to add the quantum service user in keystone
source ~/credentials/admin

# Create quantum service user in the services tenant
QUANTUM_USER_ID=`keystone user-create --tenant-id $SERVICE_TENANT_ID --name quantum --pass notquantum | awk '/ id / { print $4 }'`

# Grant admin role to quantum service user
keystone user-role-add --user-id $QUANTUM_USER_ID --tenant-id $SERVICE_TENANT_ID --role-id $ADMIN_ROLE_ID

# List the new user and role assigment
keystone user-list --tenant-id $SERVICE_TENANT_ID
keystone user-role-list --tenant-id $SERVICE_TENANT_ID --user-id $QUANTUM_USER_ID

# Configure the quantum service to use keystone
sudo sed -i 's/# auth_strategy = keystone/auth_strategy = keystone/g' /etc/quantum/quantum.conf
sudo sed -i "s/auth_host = 127.0.0.1/auth_host = $PRIVATE_IP/g" /etc/quantum/quantum.conf
sudo sed -i 's/%SERVICE_TENANT_NAME%/Services/g' /etc/quantum/quantum.conf
sudo sed -i 's/%SERVICE_USER%/quantum/g' /etc/quantum/quantum.conf
sudo sed -i 's/%SERVICE_PASSWORD%/notquantum/g' /etc/quantum/quantum.conf

# Start Open vSwitch
sudo service openvswitch-switch restart

# Create the integration and external bridges
sudo ovs-vsctl add-br br-int
sudo ovs-vsctl add-br br-ex

# Restart the quantum services
sudo service quantum-server restart
sudo service quantum-plugin-openvswitch-agent restart
sudo service quantum-dhcp-agent restart
sudo service quantum-l3-agent restart

# Use the 'user' credentials
source ~/credentials/user

# Create a network and subnet
PRIVATE_NET_ID=`quantum net-create private | awk '/ id / { print $4 }'`
PRIVATE_SUBNET1_ID=`quantum subnet-create --name private-subnet1 $PRIVATE_NET_ID 10.208.128.0/29 | awk '/ id / { print $4 }'`

# List network and subnet
quantum net-list
quantum subnet-list

# Examine details of network and subnet
quantum net-show $PRIVATE_NET_ID
quantum subnet-show $PRIVATE_SUBNET1_ID

cat >> ~/.bashrc <<EOF
export PRIVATE_NET_ID=$PRIVATE_NET_ID
export PRIVATE_SUBNET1_ID=$PRIVATE_SUBNET1_ID
EOF



####################################################################################
####################################################################################
#				Compute Service (Nova)
####################################################################################
####################################################################################

# nova-compute-kvm requires that your CPU supports hardware-assisted virtualization (HVM) such as Intel VT-x or AMD-V. If your CPU does not support this, or if you are already running in a virtualized environment, you can instead use the nova-compute-qemu package. This package provides software-based virtualization.


# Install the compute service (nova) [S L O W]
#sudo apt-get install -y nova-api nova-scheduler nova-conductor nova-compute nova-cert nova-consoleauth genisoimage
sudo apt-get install -y nova-api nova-scheduler nova-conductor nova-compute-qemu nova-cert nova-consoleauth genisoimage

# Use the 'admin' credentials to add the nova service user in keystone
source ~/credentials/admin

# Create nova service user in the services tenant
NOVA_USER_ID=`keystone user-create --tenant-id $SERVICE_TENANT_ID --name nova --pass notnova | awk '/ id / { print $4 }'`

# Grant admin role to nova service user
keystone user-role-add --user-id $NOVA_USER_ID --tenant-id $SERVICE_TENANT_ID --role-id $ADMIN_ROLE_ID

# List the new user and role assigment
keystone user-list --tenant-id $SERVICE_TENANT_ID
keystone user-role-list --tenant-id $SERVICE_TENANT_ID --user-id $NOVA_USER_ID

# Create a database for nova
mysql -u root -pnotmysql -e "CREATE DATABASE nova;"
mysql -u root -pnotmysql -e "GRANT ALL ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'notnova';"
mysql -u root -pnotmysql -e "GRANT ALL ON nova.* TO 'nova'@'$PRIVATE_IP' IDENTIFIED BY 'notnova';"
mysql -u root -pnotmysql -e "GRANT ALL ON nova.* TO 'nova'@'%' IDENTIFIED BY 'notnova';"

# Configure nova
cat <<EOF | sudo tee -a /etc/nova/nova.conf
compute_driver=libvirt.LibvirtDriver
libvirt_type=qemu
libvirt_use_virtio_for_bridges=True
network_api_class=nova.network.quantumv2.api.API
quantum_url=http://$PRIVATE_IP:9696
quantum_auth_strategy=keystone
quantum_admin_tenant_name=Services
quantum_admin_username=quantum
quantum_admin_password=notquantum
quantum_admin_auth_url=http://$PRIVATE_IP:35357/v2.0
firewall_driver=nova.virt.firewall.NoopFirewallDriver
security_group_api=quantum
sql_connection=mysql://nova:notnova@$PRIVATE_IP/nova
auth_strategy=keystone
force_config_drive=True
my_ip=$PRIVATE_IP
EOF

# Disable verbose logging
sudo sed -i 's/verbose=True/verbose=False/g' /etc/nova/nova.conf

# Configure nova to use keystone
sudo sed -i "s/auth_host = 127.0.0.1/auth_host = $PRIVATE_IP/g" /etc/nova/api-paste.ini
sudo sed -i 's/%SERVICE_TENANT_NAME%/Services/g' /etc/nova/api-paste.ini
sudo sed -i 's/%SERVICE_USER%/nova/g' /etc/nova/api-paste.ini
sudo sed -i 's/%SERVICE_PASSWORD%/notnova/g' /etc/nova/api-paste.ini

# Initialize the nova database
sudo -u nova nova-manage db sync

# Restart nova services
sudo service nova-api restart
sudo service nova-scheduler restart
sudo service nova-conductor restart
sudo service nova-compute restart
sudo service nova-cert restart
sudo service nova-consoleauth restart

# Restart the quantum services
sudo service quantum-server restart
sudo service quantum-plugin-openvswitch-agent restart
sudo service quantum-dhcp-agent restart
sudo service quantum-l3-agent restart

# Verify nova services successfully restarted
pgrep -l nova

# Verify nova services are functioning and checking in :-)
sudo nova-manage service list

# Use the 'user' credentials
source ~/credentials/user

# List images
nova image-list

# List flavors
nova flavor-list

# Boot an instance using flavor and image names (if names are unique)
nova boot --image cirros-qcow2 --flavor m1.tiny MyFirstInstance

# Boot an instance using flavor and image IDs
nova boot --image $IMAGE_ID_2 --flavor 1 MySecondInstance

# List instances, notice status of instance
nova list

# Show details of instance
nova show MyFirstInstance

# View console log of instance
nova console-log MyFirstInstance

# Get network namespace (ie, qdhcp-5ab46e23-118a-4cad-9ca8-51d56a5b6b8c)
sudo ip netns
NETNS_ID=qdhcp-$PRIVATE_NET_ID

# Ping first instance after status is active
sudo ip netns exec $NETNS_ID ping -c 3 10.208.128.3

# Log into first instance ( username is 'cirros', password is 'cubswin:)' )
sudo ip netns exec $NETNS_ID ssh cirros@10.208.128.3

# If you get a 'REMOTE HOST IDENTIFICATION HAS CHANGED' warning from previous command
sudo ssh-keygen -f "/root/.ssh/known_hosts" -R 10.208.128.3

# Ping second instance from first instance
ping -c 3 10.208.128.4

# Log into second instance from first instance ( username is 'cirros', password is 'cubswin:)' )
ssh cirros@10.208.128.4

# Log out of second instance
exit

# Log out of first instance
exit

# Use virsh to talk directly to libvirt
sudo virsh list --all

# Delete instances
nova delete MyFirstInstance
nova delete MySecondInstance

# List instances, notice status of instance
nova list

cat >> ~/.bashrc <<EOF
export NETNS_ID=$NETNS_ID
EOF


####################################################################################
####################################################################################
#				Volume Service (Cinder)
####################################################################################
####################################################################################

# Install the volume service (cinder)
sudo apt-get install -y cinder-api cinder-scheduler cinder-volume

# Use the 'admin' credentials to add the cinder service user in keystone
source ~/credentials/admin

# Create cinder service user in the services tenant
CINDER_USER_ID=`keystone user-create --tenant-id $SERVICE_TENANT_ID --name cinder --pass notcinder | awk '/ id / { print $4 }'`

# Grant admin role to cinder service user
keystone user-role-add --user-id $CINDER_USER_ID --tenant-id $SERVICE_TENANT_ID --role-id $ADMIN_ROLE_ID

# List the new user and role assigment
keystone user-list --tenant-id $SERVICE_TENANT_ID
keystone user-role-list --tenant-id $SERVICE_TENANT_ID --user-id $CINDER_USER_ID

# Create a database for cinder
mysql -u root -pnotmysql -e "CREATE DATABASE cinder;"
mysql -u root -pnotmysql -e "GRANT ALL ON cinder.* TO 'cinder'@'localhost' IDENTIFIED BY 'notcinder';"
mysql -u root -pnotmysql -e "GRANT ALL ON cinder.* TO 'cinder'@'$PRIVATE_IP' IDENTIFIED BY 'notcinder';"
mysql -u root -pnotmysql -e "GRANT ALL ON cinder.* TO 'cinder'@'%' IDENTIFIED BY 'notcinder';"

# Configure cinder
( cat | sudo tee -a /etc/cinder/cinder.conf ) <<EOF
sql_connection = mysql://cinder:notcinder@$PRIVATE_IP/cinder
my_ip = $PRIVATE_IP
EOF

# Configure cinder-api to use keystone
sudo sed -i "s/service_host = 127.0.0.1/service_host = $PRIVATE_IP/g" /etc/cinder/api-paste.ini
sudo sed -i "s/auth_host = 127.0.0.1/auth_host = $PRIVATE_IP/g" /etc/cinder/api-paste.ini
sudo sed -i 's/admin_tenant_name = %SERVICE_TENANT_NAME%/admin_tenant_name = Services/g' /etc/cinder/api-paste.ini
sudo sed -i 's/admin_user = %SERVICE_USER%/admin_user = cinder/g' /etc/cinder/api-paste.ini
sudo sed -i 's/admin_password = %SERVICE_PASSWORD%/admin_password = notcinder/g' /etc/cinder/api-paste.ini

# Initialize the database schema
sudo -u cinder cinder-manage db sync

# Configure nova to use cinder
( cat | sudo tee -a /etc/nova/nova.conf ) <<EOF
volume_manager=cinder.volume.manager.VolumeManager
volume_api_class=nova.volume.cinder.API
enabled_apis=osapi_compute
EOF

# Restart nova-api to disable the nova-volume api (osapi_volume)
sudo service nova-api restart
sudo service nova-scheduler restart
sudo service nova-conductor restart
sudo service nova-compute restart
sudo service nova-cert restart
sudo service nova-consoleauth restart

# Restart the quantum services
sudo service quantum-server restart
sudo service quantum-plugin-openvswitch-agent restart
sudo service quantum-dhcp-agent restart
sudo service quantum-l3-agent restart

# Configure tgt
( cat | sudo tee -a /etc/tgt/targets.conf ) <<EOF
default-driver iscsi
EOF

# Restart tgt and open-iscsi
sudo service tgt restart
sudo service open-iscsi restart

# Create the volume group
sudo pvcreate /dev/xvdb
sudo vgcreate cinder-volumes /dev/xvdb

# Verify the volume group
sudo vgdisplay

# Restart the volume services
sudo service cinder-volume restart
sudo service cinder-scheduler restart
sudo service cinder-api restart

# Use the 'user' credentials
source ~/credentials/user

# Create a new volume
cinder create 1 --display-name MyFirstVolume

# Boot an instance to attach volume to
nova boot --image cirros-qcow2 --flavor m1.tiny MyVolumeInstance

# List instances, notice status of instance
nova list

# List volumes, notice status of volume
cinder list

# Attach volume to instance after instance is active, and volume is available
nova volume-attach <instance-id> <volume-id> /dev/vdc

# Log into first instance ( username is 'cirros', password is 'cubswin:)' )
sudo ip netns exec $NETNS_ID ssh cirros@10.208.128.3

# If you get a 'REMOTE HOST IDENTIFICATION HAS CHANGED' warning from previous command
sudo ssh-keygen -f "/root/.ssh/known_hosts" -R 10.208.128.3

# Make filesystem on volume
sudo mkfs.ext3 /dev/vdc

# Create a mountpoint
sudo mkdir /extraspace

# Mount the volume at the mountpoint
sudo mount /dev/vdc /extraspace

# Create a file on the volume
sudo touch /extraspace/helloworld.txt
sudo ls /extraspace

# Unmount the volume
sudo umount /extraspace

# Log out of instance
exit

# Detach volume from instance
nova volume-detach <instance-id> <volume-id>

# List volumes, notice status of volume
cinder list

# Delete instance
nova delete MyVolumeInstance

# From the dashboard, try booting another instance, attach volume to new instance, and mount volume. Data should be preserved on volume.


####################################################################################
####################################################################################
#				Dashboard (Horizon)
####################################################################################
####################################################################################


# Install dependencies
sudo apt-get install -y memcached novnc

# Install the dashboard (horizon)
sudo apt-get install -y openstack-dashboard nova-novncproxy

# Remove the Ubuntu theme
sudo apt-get remove -y --purge openstack-dashboard-ubuntu-theme

# Configure nova for VNC
( cat | sudo tee -a /etc/nova/nova.conf ) <<EOF
novncproxy_base_url=http://$PUBLIC_IP:6080/vnc_auto.html
vncserver_proxyclient_address=$PRIVATE_IP
vncserver_listen=0.0.0.0
novnc_enable=true
EOF

# Set default role
sudo sed -i 's/OPENSTACK_KEYSTONE_DEFAULT_ROLE = "Member"/OPENSTACK_KEYSTONE_DEFAULT_ROLE = "_member_"/g' /etc/openstack-dashboard/local_settings.py

# Restart the nova services
sudo service nova-api restart
sudo service nova-scheduler restart
sudo service nova-conductor restart
sudo service nova-compute restart
sudo service nova-cert restart
sudo service nova-consoleauth restart
sudo service apache2 restart

# Point your browser to http://10.0.0.X/horizon

####################################################################################
####################################################################################
#				Keypairs
####################################################################################
####################################################################################


# Create a nova keypair, saving private key
nova keypair-add MyKeypair > MyKeypair.pem

# Change private key permissions
chmod 600 MyKeypair.pem

# Boot an instance using the keypair
nova boot --image cirros-qcow2 --flavor m1.tiny --key-name MyKeypair MyKeypairInstance

# List instances, notice status of instance
nova list

# Ping instance after status is active
sudo ip netns exec $NETNS_ID ping -c 3 10.208.128.3

# Log into first instance ( you should be logged right into a shell, no password necessary )
sudo ip netns exec $NETNS_ID ssh -i MyKeypair.pem cirros@10.208.128.3

# If you get a 'REMOTE HOST IDENTIFICATION HAS CHANGED' warning from previous command
sudo ssh-keygen -f "/root/.ssh/known_hosts" -R 10.208.128.3

# Log out of instance
exit

# Delete instance
nova delete MyKeypairInstance

# List instances, notice status of instance
nova list

# From the dashboard, try booting an instance using the keypair


####################################################################################
####################################################################################
#				
####################################################################################
####################################################################################

